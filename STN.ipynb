{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocatlizationNetwork(nn.Module):\n",
    "    # 定位出K個基準點\n",
    "    # 一個點由(x,y)定義，所以會有2K個輸出\n",
    "    \n",
    "    def __init__(self, K, input_channel):\n",
    "        super(LocatlizationNetwork, self).__init__()\n",
    "        self.K = K\n",
    "        self.input_channel = input_channel\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.input_channel, out_channels=64, \n",
    "                      kernel_size=(3,3), stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, (3,3), 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, (3,3), 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, (3,3), 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "        \n",
    "        self.location_fc1 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.location_fc2 = nn.Linear(1024, 2*K)\n",
    "        self.tanh = nn.Tanh() # 範圍[-1, 1]\n",
    "        \n",
    "        # initialized fc2 weight \n",
    "        self.location_fc2.weight.data.fill_(0)\n",
    "        \n",
    "        # initialized fc2 weight and bias\n",
    "        pt_x = np.linspace(-1.0, 1.0, int(K/2)) # 產生基準點的x座標\n",
    "        pt_y_top = np.linspace(0.0, -1.0, int(K/2)) # 產生上半部基準點的y座標\n",
    "        pt_y_bottom = np.linspace(1, 0.0, int(K/2)) # 產生下半部基準點的y座標\n",
    "        pt_top = np.stack([pt_x, pt_y_top], axis=1) # 上半部基準點\n",
    "        pt_bottom = np.stack([pt_x, pt_y_bottom], axis=1) # 下半部基準點\n",
    "        init_bias = np.concatenate([pt_top, pt_bottom], axis=0)\n",
    "        self.location_fc2.bias.data = torch.from_numpy(init_bias).float().view(-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.location_fc1(out)\n",
    "        out = self.location_fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocatlizationNetwork(20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 100, 32]           1,728\n",
      "       BatchNorm2d-2          [-1, 64, 100, 32]             128\n",
      "              ReLU-3          [-1, 64, 100, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 50, 16]               0\n",
      "            Conv2d-5          [-1, 128, 50, 16]          73,728\n",
      "       BatchNorm2d-6          [-1, 128, 50, 16]             256\n",
      "              ReLU-7          [-1, 128, 50, 16]               0\n",
      "         MaxPool2d-8           [-1, 128, 25, 8]               0\n",
      "            Conv2d-9           [-1, 256, 25, 8]         294,912\n",
      "      BatchNorm2d-10           [-1, 256, 25, 8]             512\n",
      "             ReLU-11           [-1, 256, 25, 8]               0\n",
      "        MaxPool2d-12           [-1, 256, 12, 4]               0\n",
      "           Conv2d-13           [-1, 512, 12, 4]       1,179,648\n",
      "      BatchNorm2d-14           [-1, 512, 12, 4]           1,024\n",
      "             ReLU-15           [-1, 512, 12, 4]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 512, 1, 1]               0\n",
      "           Linear-17                 [-1, 1024]         525,312\n",
      "             ReLU-18                 [-1, 1024]               0\n",
      "           Linear-19                   [-1, 40]          41,000\n",
      "             Tanh-20                   [-1, 40]               0\n",
      "================================================================\n",
      "Total params: 2,118,248\n",
      "Trainable params: 2,118,248\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 9.47\n",
      "Params size (MB): 8.08\n",
      "Estimated Total Size (MB): 17.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 100, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試一個batch中有兩張100*32的影像輸入到localization network後的結果\n",
    "input = torch.randn(2, 3, 100, 32)\n",
    "\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7616,  0.0000, -0.6514, -0.1107, -0.5047, -0.2186, -0.3215, -0.3215,\n",
       "        -0.1107, -0.4173,  0.1107, -0.5047,  0.3215, -0.5828,  0.5047, -0.6514,\n",
       "         0.6514, -0.7108,  0.7616, -0.7616, -0.7616,  0.7616, -0.6514,  0.7108,\n",
       "        -0.5047,  0.6514, -0.3215,  0.5828, -0.1107,  0.5047,  0.1107,  0.4173,\n",
       "         0.3215,  0.3215,  0.5047,  0.2186,  0.6514,  0.1107,  0.7616,  0.0000],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
